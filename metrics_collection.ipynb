{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "metrics-collection-intro",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Automated Delta Lake Optimization Metrics Collection\n",
    "\n",
    "This companion notebook provides automated metrics collection and visualization capabilities for the Delta Lake optimization project. It demonstrates how to programmatically capture performance metrics and store them in a Delta table for trend analysis.\n",
    "\n",
    "## Features\n",
    "- Automated metrics capture from Spark UI and table metadata\n",
    "- Storage of metrics in a Delta table for historical tracking\n",
    "- Visualization of performance improvements over time\n",
    "- Comparison utilities for different optimization techniques\n",
    "\n",
    "## Prerequisites\n",
    "Run the main `project.ipynb` notebook first to create the base tables and complete at least a few optimization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "metrics-setup",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration - must match main project settings\n",
    "CATALOG_NAME = \"delta_optimization_project\"\n",
    "SCHEMA_NAME = \"sales_data\"\n",
    "METRICS_TABLE = f\"{CATALOG_NAME}.{SCHEMA_NAME}.optimization_metrics\"\n",
    "\n",
    "# Ensure we're using the right catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA_NAME}\")\n",
    "\n",
    "# Import required libraries\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "metrics-schema",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define metrics collection schema\n",
    "metrics_schema = StructType([\n",
    "    StructField(\"experiment_id\", StringType(), False),\n",
    "    StructField(\"timestamp\", TimestampType(), False),\n",
    "    StructField(\"table_name\", StringType(), False),\n",
    "    StructField(\"optimization_technique\", StringType(), False),\n",
    "    StructField(\"step_number\", IntegerType(), False),\n",
    "    StructField(\"query_description\", StringType(), True),\n",
    "    StructField(\"files_scanned\", LongType(), True),\n",
    "    StructField(\"bytes_read\", LongType(), True),\n",
    "    StructField(\"duration_ms\", LongType(), True),\n",
    "    StructField(\"output_rows\", LongType(), True),\n",
    "    StructField(\"num_files_total\", LongType(), True),\n",
    "    StructField(\"table_size_bytes\", LongType(), True),\n",
    "    StructField(\"avg_file_size_mb\", DoubleType(), True),\n",
    "    StructField(\"additional_metrics\", StringType(), True)  # JSON for extensibility\n",
    "])\n",
    "\n",
    "# Create metrics table if it doesn't exist\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {METRICS_TABLE} (\n",
    "    experiment_id STRING NOT NULL,\n",
    "    timestamp TIMESTAMP NOT NULL,\n",
    "    table_name STRING NOT NULL,\n",
    "    optimization_technique STRING NOT NULL,\n",
    "    step_number INT NOT NULL,\n",
    "    query_description STRING,\n",
    "    files_scanned BIGINT,\n",
    "    bytes_read BIGINT,\n",
    "    duration_ms BIGINT,\n",
    "    output_rows BIGINT,\n",
    "    num_files_total BIGINT,\n",
    "    table_size_bytes BIGINT,\n",
    "    avg_file_size_mb DOUBLE,\n",
    "    additional_metrics STRING\n",
    ") USING DELTA\n",
    "TBLPROPERTIES (\n",
    "    'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "    'delta.autoOptimize.autoCompact' = 'true'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Metrics table created/verified: {METRICS_TABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "metrics-collector-class",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class DeltaOptimizationMetricsCollector:\n",
    "    \"\"\"Automated metrics collection for Delta Lake optimization experiments.\"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_id=None):\n",
    "        self.experiment_id = experiment_id or f\"exp_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        self.metrics_table = METRICS_TABLE\n",
    "        \n",
    "    def capture_table_metadata(self, table_name):\n",
    "        \"\"\"Capture table metadata like file count, size, etc.\"\"\"\n",
    "        try:\n",
    "            detail_df = spark.sql(f\"DESCRIBE DETAIL {table_name}\")\n",
    "            detail = detail_df.collect()[0]\n",
    "            \n",
    "            num_files = detail['numFiles'] if detail['numFiles'] else 0\n",
    "            size_bytes = detail['sizeInBytes'] if detail['sizeInBytes'] else 0\n",
    "            avg_file_size_mb = (size_bytes / num_files / 1024 / 1024) if num_files > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'num_files_total': num_files,\n",
    "                'table_size_bytes': size_bytes,\n",
    "                'avg_file_size_mb': avg_file_size_mb\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error capturing table metadata: {e}\")\n",
    "            return {'num_files_total': None, 'table_size_bytes': None, 'avg_file_size_mb': None}\n",
    "    \n",
    "    def record_query_metrics(self, \n",
    "                           table_name, \n",
    "                           optimization_technique, \n",
    "                           step_number,\n",
    "                           query_description=None,\n",
    "                           files_scanned=None,\n",
    "                           bytes_read=None,\n",
    "                           duration_ms=None,\n",
    "                           output_rows=None,\n",
    "                           additional_metrics=None):\n",
    "        \"\"\"Record query execution metrics.\"\"\"\n",
    "        \n",
    "        # Capture table metadata\n",
    "        table_meta = self.capture_table_metadata(table_name)\n",
    "        \n",
    "        # Prepare metrics record\n",
    "        metrics_record = {\n",
    "            'experiment_id': self.experiment_id,\n",
    "            'timestamp': datetime.datetime.now(),\n",
    "            'table_name': table_name,\n",
    "            'optimization_technique': optimization_technique,\n",
    "            'step_number': step_number,\n",
    "            'query_description': query_description,\n",
    "            'files_scanned': files_scanned,\n",
    "            'bytes_read': bytes_read,\n",
    "            'duration_ms': duration_ms,\n",
    "            'output_rows': output_rows,\n",
    "            'additional_metrics': json.dumps(additional_metrics) if additional_metrics else None\n",
    "        }\n",
    "        \n",
    "        # Add table metadata\n",
    "        metrics_record.update(table_meta)\n",
    "        \n",
    "        # Insert into metrics table\n",
    "        metrics_df = spark.createDataFrame([metrics_record], metrics_schema)\n",
    "        metrics_df.write.mode(\"append\").saveAsTable(self.metrics_table)\n",
    "        \n",
    "        print(f\"üìä Metrics recorded for {optimization_technique} on {table_name}\")\n",
    "        return metrics_record\n",
    "    \n",
    "    def benchmark_query(self, query, table_name, optimization_technique, step_number, query_description=None):\n",
    "        \"\"\"Execute a query and automatically capture its metrics.\"\"\"\n",
    "        import time\n",
    "        \n",
    "        print(f\"üîç Executing benchmark query: {query_description or 'Query'}\")\n",
    "        \n",
    "        # Execute query and measure time\n",
    "        start_time = time.time()\n",
    "        result_df = spark.sql(query)\n",
    "        output_rows = result_df.count()  # This forces execution\n",
    "        end_time = time.time()\n",
    "        \n",
    "        duration_ms = int((end_time - start_time) * 1000)\n",
    "        \n",
    "        # Note: In a real Databricks environment, you would extract files_scanned \n",
    "        # and bytes_read from the Spark UI or query plan. For this demo, we'll \n",
    "        # set them as None and rely on manual input or future enhancement.\n",
    "        \n",
    "        # Record metrics\n",
    "        metrics = self.record_query_metrics(\n",
    "            table_name=table_name,\n",
    "            optimization_technique=optimization_technique,\n",
    "            step_number=step_number,\n",
    "            query_description=query_description,\n",
    "            duration_ms=duration_ms,\n",
    "            output_rows=output_rows,\n",
    "            additional_metrics={'query': query}\n",
    "        )\n",
    "        \n",
    "        print(f\"‚è±Ô∏è Query completed in {duration_ms}ms, returned {output_rows} rows\")\n",
    "        return result_df, metrics\n",
    "\n",
    "# Create a global instance for easy use\n",
    "metrics_collector = DeltaOptimizationMetricsCollector()\n",
    "\n",
    "print(f\"‚úÖ Metrics collector initialized with experiment ID: {metrics_collector.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "usage-examples",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Usage Examples\n",
    "\n",
    "Here are examples of how to use the automated metrics collection system in your optimization experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "example-usage",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example 1: Benchmark a query automatically\n",
    "# This would typically be run after each optimization step in the main notebook\n",
    "\n",
    "sample_query = \"\"\"\n",
    "SELECT country, \n",
    "       COUNT(*) as total_sales,\n",
    "       SUM(amount) as total_revenue\n",
    "FROM delta_optimization_project.sales_data.sales_raw \n",
    "WHERE country IN ('USA', 'Germany', 'France')\n",
    "GROUP BY country\n",
    "\"\"\"\n",
    "\n",
    "# Check if the table exists before running the example\n",
    "try:\n",
    "    spark.sql(\"DESCRIBE TABLE delta_optimization_project.sales_data.sales_raw\")\n",
    "    table_exists = True\n",
    "except:\n",
    "    table_exists = False\n",
    "    print(\"‚ÑπÔ∏è Main project tables not found. Run project.ipynb first to create sample data.\")\n",
    "\n",
    "if table_exists:\n",
    "    result_df, metrics = metrics_collector.benchmark_query(\n",
    "        query=sample_query,\n",
    "        table_name=\"delta_optimization_project.sales_data.sales_raw\",\n",
    "        optimization_technique=\"baseline\",\n",
    "        step_number=1,\n",
    "        query_description=\"Country aggregation baseline\"\n",
    "    )\n",
    "    \n",
    "    display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "example-manual-metrics",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example 2: Record metrics manually (when you have Spark UI data)\n",
    "# This approach allows you to input specific metrics from the Spark UI\n",
    "\n",
    "if table_exists:\n",
    "    manual_metrics = metrics_collector.record_query_metrics(\n",
    "        table_name=\"delta_optimization_project.sales_data.sales_raw\",\n",
    "        optimization_technique=\"partitioned\",\n",
    "        step_number=2,\n",
    "        query_description=\"After country partitioning\",\n",
    "        files_scanned=50,  # From Spark UI\n",
    "        bytes_read=1024*1024*100,  # 100 MB from Spark UI\n",
    "        duration_ms=2500,\n",
    "        output_rows=3,\n",
    "        additional_metrics={\n",
    "            \"scan_efficiency\": \"high\",\n",
    "            \"partition_pruning\": True\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "visualization-section",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Metrics Visualization\n",
    "\n",
    "Visualize the performance improvements across different optimization techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "visualization-functions",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_performance_comparison():\n",
    "    \"\"\"Create a performance comparison visualization.\"\"\"\n",
    "    \n",
    "    # Query metrics data\n",
    "    metrics_df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        optimization_technique,\n",
    "        step_number,\n",
    "        AVG(duration_ms) as avg_duration_ms,\n",
    "        AVG(files_scanned) as avg_files_scanned,\n",
    "        AVG(bytes_read / 1024 / 1024) as avg_mb_read,\n",
    "        AVG(avg_file_size_mb) as avg_file_size_mb,\n",
    "        COUNT(*) as measurement_count\n",
    "    FROM {METRICS_TABLE}\n",
    "    WHERE duration_ms IS NOT NULL\n",
    "    GROUP BY optimization_technique, step_number\n",
    "    ORDER BY step_number\n",
    "    \"\"\")\n",
    "    \n",
    "    if metrics_df.count() > 0:\n",
    "        display(metrics_df)\n",
    "        \n",
    "        print(\"\\nüìà Performance Trends:\")\n",
    "        print(\"‚Ä¢ Lower duration_ms = better query performance\")\n",
    "        print(\"‚Ä¢ Lower files_scanned = better file pruning\")\n",
    "        print(\"‚Ä¢ Higher avg_file_size_mb = better file consolidation\")\n",
    "    else:\n",
    "        print(\"üìä No metrics data available yet. Run some benchmarks first!\")\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def show_file_size_trends():\n",
    "    \"\"\"Show how file sizes change with different optimizations.\"\"\"\n",
    "    \n",
    "    file_trends = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        table_name,\n",
    "        optimization_technique,\n",
    "        step_number,\n",
    "        num_files_total,\n",
    "        ROUND(table_size_bytes / 1024 / 1024, 2) as table_size_mb,\n",
    "        ROUND(avg_file_size_mb, 2) as avg_file_size_mb,\n",
    "        timestamp\n",
    "    FROM {METRICS_TABLE}\n",
    "    WHERE num_files_total IS NOT NULL\n",
    "    ORDER BY table_name, step_number, timestamp DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    if file_trends.count() > 0:\n",
    "        print(\"üìÅ File Size Evolution:\")\n",
    "        display(file_trends)\n",
    "        \n",
    "        # Calculate improvement ratios\n",
    "        baseline_files = file_trends.filter(F.col(\"step_number\") == 1).select(\"num_files_total\").collect()\n",
    "        if baseline_files:\n",
    "            baseline_count = baseline_files[0][\"num_files_total\"]\n",
    "            print(f\"\\nüéØ Optimization Impact (vs baseline of {baseline_count} files):\")\n",
    "            \n",
    "            improvements = file_trends.withColumn(\n",
    "                \"file_reduction_ratio\", \n",
    "                F.round((F.lit(baseline_count) - F.col(\"num_files_total\")) / F.lit(baseline_count) * 100, 1)\n",
    "            ).select(\"optimization_technique\", \"num_files_total\", \"file_reduction_ratio\")\n",
    "            \n",
    "            display(improvements)\n",
    "    else:\n",
    "        print(\"üìÅ No file size data available yet.\")\n",
    "    \n",
    "    return file_trends\n",
    "\n",
    "# Create visualizations\n",
    "print(\"üîç Generating performance analysis...\\n\")\n",
    "perf_comparison = create_performance_comparison()\n",
    "file_trends = show_file_size_trends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "integration-guide",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Integration with Main Project\n",
    "\n",
    "To integrate this automated metrics collection with the main `project.ipynb` notebook, add these code snippets after each optimization step:\n",
    "\n",
    "### Step 1: Initialize (add to main notebook setup)\n",
    "```python\n",
    "# Import metrics collection\n",
    "%run \"./metrics_collection\"\n",
    "\n",
    "# Initialize collector\n",
    "metrics = DeltaOptimizationMetricsCollector(\"my_experiment_2024\")\n",
    "```\n",
    "\n",
    "### Step 2: After each query (replace manual tracking)\n",
    "```python\n",
    "# Instead of manually recording metrics, use:\n",
    "result_df, metrics_data = metrics.benchmark_query(\n",
    "    query=\"SELECT * FROM sales_table WHERE country = 'USA'\",\n",
    "    table_name=\"sales_table\",\n",
    "    optimization_technique=\"partitioned\",\n",
    "    step_number=3,\n",
    "    query_description=\"Country filter after partitioning\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Step 3: View results\n",
    "```python\n",
    "# Generate performance comparison\n",
    "create_performance_comparison()\n",
    "```\n",
    "\n",
    "This approach provides:\n",
    "- ‚úÖ Automated data collection\n",
    "- ‚úÖ Historical trend tracking\n",
    "- ‚úÖ Visual performance comparisons\n",
    "- ‚úÖ Reproducible experiments\n",
    "- ‚úÖ Extensible metrics schema"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "metrics_collection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}